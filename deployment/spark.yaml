services:
  spark-master:
    image: spark:3.5.0-python3
    container_name: spark-master
    ports:
      - "8085:8080"
      # - "7077:7077"
    environment:
      - INIT_DAEMON_STEP=setup_spark
    networks:
      - net
    command: >
      bash -c "cd /opt/spark/sbin/ && bash start-master.sh && tail -f /dev/null"
      
  spark-worker-1:
    image: spark:3.5.0-python3
    container_name: spark-worker-1
    depends_on:
      - spark-master
    env_file:
      - ./spark.env
    networks:
      - net
    command: >
      bash -c "cd /opt/spark/sbin/ && bash start-worker.sh $$SPARK_MASTER -c $$CORE_PER_SPARK_WORKER -m $$MEM_PER_SPARK_WORKER && tail -f /dev/null"
  
  spark-worker-2:
    image: spark:3.5.0-python3
    container_name: spark-worker-2
    depends_on:
      - spark-master
    env_file:
      - ./spark.env
    networks:
      - net
    command: >
      bash -c "cd /opt/spark/sbin/ && bash start-worker.sh $$SPARK_MASTER -c $$CORE_PER_SPARK_WORKER -m $$MEM_PER_SPARK_WORKER && tail -f /dev/null"
    

  spark-client:
    image: spark:3.5.0-jupyter-client
    build: ../spark_client/
    container_name: spark-client
    depends_on:
      - spark-master
      - spark-worker-1
      - spark-worker-2
    ports:
      - "8888:8888"
    env_file:
      - ./spark.env
    volumes:
      - ../spark_client:/app
      - ../data/spark-client:/app/data
    networks:
      - net